{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#긍정리뷰 파일들을 로딩\n",
    "pos_review=(glob.glob(\"d:/data/imdb/train/pos/*.txt\"))\n",
    "#print(pos_review)\n",
    "lines_pos=[]\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f=open(i, \"r\") #읽기 모드로 파일 오픈\n",
    "        temp=f.readlines()[0] \n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        \n",
    "print(len(lines_pos)) #12490건의 긍정 리뷰\n",
    "print(lines_pos[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#긍정리뷰 파일들을 로딩\n",
    "neg_review=(glob.glob(\"d:/data/imdb/train/neg/*.txt\"))\n",
    "#print(pos_review)\n",
    "lines_neg=[]\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f=open(i, \"r\") #읽기 모드로 파일 오픈\n",
    "        temp=f.readlines()[0] \n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        \n",
    "print(len(lines_neg)) #12489건의 부정 리뷰\n",
    "print(lines_neg[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정,부정 리뷰를 합침\n",
    "total_text=lines_pos + lines_neg\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "#긍정,부정 클래스에 라벨링\n",
    "x= np.array([\"pos\",\"neg\"])\n",
    "class_Index=np.repeat(x, [len(lines_pos), len(lines_neg)],\n",
    "                     axis=0)\n",
    "print(len(class_Index))\n",
    "print(class_Index)\n",
    "stop_words=stopwords.words(\"english\") #영어 불용어 사전\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#불용어를 제거, 단어들에 Tfidf 가중치를 부여한 후 \n",
    "#문서-단어 행렬로 변환하는 코드\n",
    "vect=TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "X_train_vectorized=vect.transform(total_text)\n",
    "X_train_vectorized.index=class_Index\n",
    "print(X_train_vectorized[:1])\n",
    "print(class_Index[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로지스틱 회귀분석\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit=LogisticRegression(random_state=10)\n",
    "logit.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 리뷰의 예측 정확도를 계산하는 함수\n",
    "def pos_review(model):\n",
    "    count_all=0 #전체 카운트 변수\n",
    "    count=0 # 긍정 리뷰를 카운트하는 변수\n",
    "    num=10 # 실험횟수\n",
    "    tests1=[]\n",
    "    for idx in range(0,num):\n",
    "        # 0~99 인덱스에 해당하는 리뷰 문서를 불러옴\n",
    "        pos_review_test=(glob.glob(\"d:/data/imdb/test/pos/*.txt\"))[idx]\n",
    "        f=open(pos_review_test,\"r\",encoding=\"utf-8\")\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "        \n",
    "        for test in tests1:\n",
    "            preds=model.predict(vect.transform(test)) #예측값 계산\n",
    "            result=preds[0]\n",
    "            #print(result)\n",
    "            if result==\"pos\": #긍정으로 예측했으면 카운트 증가 처리\n",
    "                count+=1\n",
    "            count_all += 1\n",
    "    rate=count*100 / count_all\n",
    "    print(\"예측 정확도:{0:.1f}%\".format(rate))\n",
    "    \n",
    "pos_review(logit)  #함수 호출  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부정 리뷰의 예측 정확도를 계산하는 함수\n",
    "def neg_review(model):\n",
    "    count_all=0 #전체 카운트 변수\n",
    "    count=0 # 부정 리뷰를 카운트하는 변수\n",
    "    num=10 # 실험횟수\n",
    "    tests2=[]\n",
    "    for idx in range(0,num):\n",
    "        # 0~99 인덱스에 해당하는 리뷰 문서를 불러옴\n",
    "        neg_review_test=(glob.glob(\"d:/data/imdb/test/neg/*.txt\"))[idx]\n",
    "        f=open(neg_review_test,\"r\",encoding=\"utf-8\")\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "        \n",
    "        for test in tests2:\n",
    "            preds=model.predict(vect.transform(test)) #예측값 계산\n",
    "            result=preds[0]\n",
    "            #print(result)\n",
    "            if result==\"neg\": #부정으로 예측했으면 카운트 증가 처리\n",
    "                count+=1\n",
    "            count_all += 1\n",
    "    rate=count*100 / count_all\n",
    "    print(\"예측 정확도:{0:.1f}%\".format(rate))\n",
    "    \n",
    "neg_review(logit)  #함수 호출  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#의사결정나무 모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review(tree) #학습용\n",
    "neg_review(tree) #검증용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트 모형\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(n_estimators=100,random_state=10) #트리갯수 100개\n",
    "forest.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review(forest) #학습용\n",
    "neg_review(forest) #검증용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN 모형\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=2) #2개의 이웃\n",
    "knn.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인공신경망\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp=MLPClassifier(random_state=10)\n",
    "mlp.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(random_state=10)\n",
    "svm.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
